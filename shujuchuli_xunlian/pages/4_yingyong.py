import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
import os
from datetime import datetime
import io

# from xianglianghua import data_preprocessing,clear_all,load_data

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®åº”ç”¨ç»ƒä¹ ",   
    layout="wide",    
    initial_sidebar_state="expanded"  
)

# ç¼“å­˜æ•°æ®åŠ è½½
@st.cache_data
def load_data(uploaded_file):
    try:
        return pd.read_csv(uploaded_file)
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return None

def in_fo(data_copy):
    """æ•°æ®å¹²å‡€åº¦æˆ–æ•°æ®ç±»å‹"""
    with st.expander("æ•°æ®å¹²å‡€åº¦æˆ–æ•°æ®ç±»å‹",expanded=False):
        buffer = io.StringIO()
        data_copy.info(buf=buffer)
        st.code(buffer.getvalue(), language='text')


def data_preprocessing(df):
    """æ•°æ®é¢„å¤„ç†å‡½æ•°"""
    st.subheader('æ•°æ®é¢„å¤„ç†')

    if 'processed_data' not in st.session_state:
        st.session_state.processed_data = df.copy()
    
    with st.form('preprocessing_form'):   
        # st.session_state.training_results = None    # â€‹å¼ºåˆ¶é‡ç½® æ¯æ¬¡è°ƒç”¨å‡½æ•°æ—¶æ¸…ç©ºå†å²ç»“æœ
        col1, col2 = st.columns(2)    
        
        with col1:
            columns_to_drop = st.multiselect(
                'é€‰æ‹©è¦åˆ é™¤çš„åˆ—',
                st.session_state.processed_data.columns,
                
                help="é€‰æ‹©ä¸éœ€è¦çš„ç‰¹å¾åˆ—"
            )
            
        with col2:
            categorical_cols = st.session_state.processed_data.select_dtypes(
                include=['object', 'category','int']).columns.tolist()  
            columns_to_encode = st.multiselect(
                'é€‰æ‹©è¦è¿›è¡Œç‹¬çƒ­ç¼–ç çš„åˆ—',
                categorical_cols,   
                
                help="é€‰æ‹©åˆ†ç±»å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç "
            )
        
        submitted = st.form_submit_button('åº”ç”¨é¢„å¤„ç†') 
    
    if submitted:
        try:
            
            if columns_to_drop:    
                st.session_state.processed_data = st.session_state.processed_data.drop(
                    columns=columns_to_drop)
            
          
            if columns_to_encode:    
                st.session_state.processed_data = pd.get_dummies(
                    st.session_state.processed_data, 
                    columns=columns_to_encode, 
                    dtype=int
                )
            
            if 'selected_features' in st.session_state:
                del st.session_state.selected_features


            st.success("é¢„å¤„ç†å®Œæˆï¼")
            show_correlation_matrix(st.session_state.processed_data)

            
        except Exception as e:
            st.error(f"é¢„å¤„ç†å‡ºé”™: {str(e)}")
    
    return st.session_state.processed_data    


def show_correlation_matrix(df):
    """æ˜¾ç¤ºç›¸å…³æ€§çŸ©é˜µ"""
    st.subheader('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ')
    try:
        corr_matrix = df.corr()  
        fig, ax = plt.subplots(figsize=(10,6))   
        sns.heatmap(
            corr_matrix,    
            annot=True,    
            fmt=".2f",     
            cmap='coolwarm',  
            center=0,    
            ax=ax      
        )
        # plt.title("ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾", pad=20)  
        st.pyplot(fig)    
    except Exception as e:
        st.warning(f"æ— æ³•è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ: {str(e)}")


def feature_selection(df):
    """ç‰¹å¾é€‰æ‹©ç•Œé¢ï¼ˆå•åˆ—å¸ƒå±€ï¼‰"""
    st.subheader('ç‰¹å¾é€‰æ‹©')    

    if 'selected_features' not in st.session_state:
        st.session_state.selected_features = []

    # ä½¿ç”¨è¡¨å•
    with st.form('feature_selection_form'):
        # å•åˆ—å¸ƒå±€ï¼ˆä¸éœ€è¦ä½¿ç”¨columnsï¼‰
        features = st.multiselect(
            'é€‰æ‹©ç‰¹å¾å˜é‡',
            df.columns,
            default=st.session_state.selected_features,    
            key='feature_select'
        )
        
        submitted = st.form_submit_button('ç¡®è®¤é€‰æ‹©')

    if submitted:
        if not features:
            st.error("âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾å˜é‡ï¼")
            return None
        
        try:
            st.session_state.selected_features = features
            st.success("âœ… ç‰¹å¾é€‰æ‹©æœ‰æ•ˆï¼")
            return df[features]
        except Exception as e:
            st.error(f"æ•°æ®é€‰æ‹©é”™è¯¯: {str(e)}")
            return None
    
    return None


def ying_yong(pickle_model, df_new_copy, df_new):
    try:
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰feature_names_in_å±æ€§
        if hasattr(pickle_model, 'feature_names_in_'):
            required_features = pickle_model.feature_names_in_
            # ç¡®ä¿æ•°æ®åŒ…å«æ‰€æœ‰éœ€è¦çš„ç‰¹å¾
            missing_features = set(required_features) - set(df_new_copy.columns)
            if missing_features:
                for feature in missing_features:
                    df_new_copy[feature] = 0  # å¡«å……ç¼ºå¤±ç‰¹å¾ä¸º0
            df_new_copy = df_new_copy[required_features]
        
        y_pred = pickle_model.predict(df_new_copy.values)
        df_new['predict'] = y_pred
        st.dataframe(df_new)
    except Exception as e:
        st.error(f"é¢„æµ‹å‡ºé”™: {str(e)}")


def clear_all():
    """æ¸…ç©ºä¼šè¯çŠ¶æ€å’Œç¼“å­˜ï¼ˆåŒ…æ‹¬è·¨é¡µé¢æ•°æ®ï¼‰"""
    # 1. è·å–å½“å‰ä¼šè¯çš„æ‰€æœ‰é”®
    current_keys = list(st.session_state.keys())
    
    # 2. ä¿ç•™å¿…è¦çš„ç³»ç»Ÿçº§é”®ï¼ˆå¯é€‰ï¼‰
    keep_keys = ['_pages', '_session_id']  # Streamlitå†…éƒ¨ä½¿ç”¨çš„é”®
    
    # 3. åˆ é™¤éç³»ç»Ÿé”®
    for key in current_keys:
        if key not in keep_keys:
            del st.session_state[key]
    
    # 4. æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
    st.cache_data.clear()
    st.cache_resource.clear()
    
    # 5. å¼ºåˆ¶é‡ç½®é¡µé¢ï¼ˆå¯é€‰ï¼‰
    st.rerun()

def main():
    st.title("æ¨¡å‹åº”ç”¨")   

    if st.button("é‡ç½®æ‰€æœ‰æ•°æ®"):
        clear_all()

    uploaded_file0 = st.file_uploader('é€‰æ‹©æœ¬åœ°æ¨¡å‹', type=['pkl'])
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ CSVæ–‡ä»¶",
        type=["csv"],
        help="è¯·ä¸Šä¼ åŒ…å«è®­ç»ƒæ•°æ®çš„CSVæ–‡ä»¶"
    )

    if (uploaded_file is not None) and (uploaded_file0 is not None):
        try:
            pickle_model = pickle.load(uploaded_file0)
            
            df = load_data(uploaded_file)

            if df is not None:
                df_new_copy = df.copy()
                with st.expander("ğŸ” æŸ¥çœ‹åŸå§‹æ•°æ®", expanded=True):
                    st.dataframe(df)
                    in_fo(df)
                
                df_processed = data_preprocessing(df_new_copy)
                if df_processed is not None:
                    df_processed_x = feature_selection(df_processed)
                    
                    if df_processed_x is not None:
                        ying_yong(pickle_model, df_processed_x, df)
                        # clear_all()
                        
        except Exception as e:
            st.error(f"åŠ è½½æ¨¡å‹æˆ–æ•°æ®å‡ºé”™: {str(e)}")


if __name__ == "__main__":
    main()
