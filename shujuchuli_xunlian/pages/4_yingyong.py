import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
import os
from datetime import datetime
import io

# from xianglianghua import data_preprocessing,clear_all,load_data

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®åº”ç”¨ç»ƒä¹ ",   
    layout="wide",    
    initial_sidebar_state="expanded"  
)

# ç¼“å­˜æ•°æ®åŠ è½½
@st.cache_data
def load_data(uploaded_file):
    try:
        return pd.read_csv(uploaded_file)
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return None


def data_preprocessing(df):
    """æ•°æ®é¢„å¤„ç†å‡½æ•°"""
    st.subheader('æ•°æ®é¢„å¤„ç†')

    if 'processed_data' not in st.session_state:
        st.session_state.processed_data = df.copy()
    
    with st.form('preprocessing_form'):   
        # st.session_state.training_results = None    # â€‹å¼ºåˆ¶é‡ç½® æ¯æ¬¡è°ƒç”¨å‡½æ•°æ—¶æ¸…ç©ºå†å²ç»“æœ
        col1, col2 = st.columns(2)    
        
        with col1:
            columns_to_drop = st.multiselect(
                'é€‰æ‹©è¦åˆ é™¤çš„åˆ—',
                st.session_state.processed_data.columns,
                
                help="é€‰æ‹©ä¸éœ€è¦çš„ç‰¹å¾åˆ—"
            )
            
        with col2:
            categorical_cols = st.session_state.processed_data.select_dtypes(
                include=['object', 'category','int']).columns.tolist()  
            columns_to_encode = st.multiselect(
                'é€‰æ‹©è¦è¿›è¡Œç‹¬çƒ­ç¼–ç çš„åˆ—',
                categorical_cols,   
                
                help="é€‰æ‹©åˆ†ç±»å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç "
            )
        
        submitted = st.form_submit_button('åº”ç”¨é¢„å¤„ç†') 
    
    if submitted:
        try:
            
            if columns_to_drop:    
                st.session_state.processed_data = st.session_state.processed_data.drop(
                    columns=columns_to_drop)
            
          
            if columns_to_encode:    
                st.session_state.processed_data = pd.get_dummies(
                    st.session_state.processed_data, 
                    columns=columns_to_encode, 
                    dtype=int
                )
            
            if 'selected_features' in st.session_state:
                del st.session_state.selected_features


            st.success("é¢„å¤„ç†å®Œæˆï¼")
            show_correlation_matrix(st.session_state.processed_data)

            
        except Exception as e:
            st.error(f"é¢„å¤„ç†å‡ºé”™: {str(e)}")
    
    return st.session_state.processed_data    


def show_correlation_matrix(df):
    """æ˜¾ç¤ºç›¸å…³æ€§çŸ©é˜µ"""
    st.subheader('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ')
    try:
        corr_matrix = df.corr()  
        fig, ax = plt.subplots(figsize=(10,6))   
        sns.heatmap(
            corr_matrix,    
            annot=True,    
            fmt=".2f",     
            cmap='coolwarm',  
            center=0,    
            ax=ax      
        )
        # plt.title("ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾", pad=20)  
        st.pyplot(fig)    
    except Exception as e:
        st.warning(f"æ— æ³•è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ: {str(e)}")


def feature_selection(df):
    """ç‰¹å¾é€‰æ‹©ç•Œé¢ï¼ˆå•åˆ—å¸ƒå±€ï¼‰"""
    st.subheader('ç‰¹å¾é€‰æ‹©')    

    if 'selected_features' not in st.session_state:
        st.session_state.selected_features = []

    # ä½¿ç”¨è¡¨å•
    with st.form('feature_selection_form'):
        # å•åˆ—å¸ƒå±€ï¼ˆä¸éœ€è¦ä½¿ç”¨columnsï¼‰
        features = st.multiselect(
            'é€‰æ‹©ç‰¹å¾å˜é‡',
            df.columns,
            default=st.session_state.selected_features,    
            key='feature_select'
        )
        
        # # æ·»åŠ æäº¤æŒ‰é’®ï¼ˆå±…ä¸­æ˜¾ç¤ºï¼‰
        # col1, col2, col3 = st.columns([1,2,1])
        # with col2:
        submitted = st.form_submit_button('ç¡®è®¤é€‰æ‹©')

    if submitted:
        if not features:
            st.error("âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾å˜é‡ï¼")
            return None
        
        try:
            st.session_state.selected_features = features
            st.success("âœ… ç‰¹å¾é€‰æ‹©æœ‰æ•ˆï¼")
            return df[features]
        except Exception as e:
            st.error(f"æ•°æ®é€‰æ‹©é”™è¯¯: {str(e)}")
            return None
    
    return None


def ying_yong(pickle_model, df_new_copy, df_new):
    try:
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰feature_names_in_å±æ€§
        if hasattr(pickle_model, 'feature_names_in_'):
            required_features = pickle_model.feature_names_in_
            # ç¡®ä¿æ•°æ®åŒ…å«æ‰€æœ‰éœ€è¦çš„ç‰¹å¾
            missing_features = set(required_features) - set(df_new_copy.columns)
            if missing_features:
                for feature in missing_features:
                    df_new_copy[feature] = 0  # å¡«å……ç¼ºå¤±ç‰¹å¾ä¸º0
            df_new_copy = df_new_copy[required_features]
        
        y_pred = pickle_model.predict(df_new_copy.values)
        df_new['predict'] = y_pred
        st.dataframe(df_new)
    except Exception as e:
        st.error(f"é¢„æµ‹å‡ºé”™: {str(e)}")


# def clear_all():
#     """æ¸…ç©ºä¼šè¯çŠ¶æ€å’Œç¼“å­˜"""
#     # æ¸…ç©ºä¼šè¯çŠ¶æ€
#     for key in list(st.session_state.keys()):
#         del st.session_state[key]
    
#     # æ¸…ç©ºç¼“å­˜ï¼ˆå¦‚æœæœ‰ä½¿ç”¨ï¼‰
#     st.cache_data.clear()
#     st.cache_resource.clear()


def clear_all():
    """æ¸…ç©ºä¼šè¯çŠ¶æ€å’Œç¼“å­˜ï¼ˆåŒ…æ‹¬è·¨é¡µé¢æ•°æ®ï¼‰"""
    # 1. è·å–å½“å‰ä¼šè¯çš„æ‰€æœ‰é”®
    current_keys = list(st.session_state.keys())
    
    # 2. ä¿ç•™å¿…è¦çš„ç³»ç»Ÿçº§é”®ï¼ˆå¯é€‰ï¼‰
    keep_keys = ['_pages', '_session_id']  # Streamlitå†…éƒ¨ä½¿ç”¨çš„é”®
    
    # 3. åˆ é™¤éç³»ç»Ÿé”®
    for key in current_keys:
        if key not in keep_keys:
            del st.session_state[key]
    
    # 4. æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
    st.cache_data.clear()
    st.cache_resource.clear()
    
    # 5. å¼ºåˆ¶é‡ç½®é¡µé¢ï¼ˆå¯é€‰ï¼‰
    st.rerun()

def main():
    st.title("æ¨¡å‹åº”ç”¨")   
    # st.session_state.training_results = None 
    # if 'data_reset' not in st.session_state:
    #     st.session_state.data_reset = False
    if st.button("é‡ç½®æ‰€æœ‰æ•°æ®"):
        clear_all()
        # st.session_state.data_reset = True
        # st.rerun()  # å…³é”®ï¼šç¡®ä¿ç•Œé¢ç«‹å³åˆ·æ–°
    uploaded_file0 = st.file_uploader('é€‰æ‹©æœ¬åœ°æ¨¡å‹', type=['pkl'])
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ CSVæ–‡ä»¶",
        type=["csv"],
        help="è¯·ä¸Šä¼ åŒ…å«è®­ç»ƒæ•°æ®çš„CSVæ–‡ä»¶"
    )

    if (uploaded_file is not None) and (uploaded_file0 is not None):
        try:
            pickle_model = pickle.load(uploaded_file0)
            
            df = load_data(uploaded_file)
            
            
            if df is not None:
                df_new_copy = df.copy()
                with st.expander("ğŸ” æŸ¥çœ‹åŸå§‹æ•°æ®", expanded=False):
                    st.dataframe(df.head())
                
                df_processed = data_preprocessing(df_new_copy)
                if df_processed is not None:
                    df_processed_x = feature_selection(df_processed)
                    
                    if df_processed_x is not None:
                        ying_yong(pickle_model, df_processed_x, df)
                        # clear_all()
                        
        except Exception as e:
            st.error(f"åŠ è½½æ¨¡å‹æˆ–æ•°æ®å‡ºé”™: {str(e)}")


if __name__ == "__main__":
    main()












# def data_preprocessing_flow(df):
#     """åµŒå¥—çš„æ•°æ®é¢„å¤„ç†æµç¨‹"""
#     st.subheader('æ•°æ®é¢„å¤„ç†')
#     with st.form('preprocessing_form'):
#         col1, col2 = st.columns(2)
        
#         with col1:
#             columns_to_drop = st.multiselect('é€‰æ‹©è¦åˆ é™¤çš„åˆ—', df.columns)
#         with col2:
#             # categorical_cols = df.select_dtypes(include=['object', 'category']).columns
#             categorical_cols = df.columns
#             columns_to_encode = st.multiselect('é€‰æ‹©ç‹¬çƒ­ç¼–ç åˆ—', categorical_cols)
        
#         if st.form_submit_button('åº”ç”¨é¢„å¤„ç†'):
#             try:
#                 # æ‰§è¡Œä¿®æ”¹
#                 if columns_to_drop:
#                     df = df.drop(columns=columns_to_drop)
#                 if columns_to_encode:
#                     df = pd.get_dummies(df, columns=columns_to_encode, dtype=int)
                
#                 st.success("é¢„å¤„ç†å®Œæˆï¼")
#                 show_correlation_matrix(df)
#                 return df  # è¿”å›ä¿®æ”¹åçš„æ•°æ®
#             except Exception as e:
#                 st.error(f"é¢„å¤„ç†å‡ºé”™: {str(e)}")
    
#     return df  # é»˜è®¤è¿”å›åŸæ•°æ®


# def show_correlation_matrix(df):
#     """æ˜¾ç¤ºç›¸å…³æ€§çŸ©é˜µ"""
#     st.subheader('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ')
#     try:
#         corr_matrix = df.corr()  
#         fig, ax = plt.subplots(figsize=(10,6))   
#         sns.heatmap(
#             corr_matrix,    
#             annot=True,    
#             fmt=".2f",     
#             cmap='coolwarm',  
#             center=0,    
#             ax=ax      
#         )
#         # plt.title("ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾", pad=20)  
#         st.pyplot(fig)    
#     except Exception as e:
#         st.warning(f"æ— æ³•è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ: {str(e)}")


# def feature_selection_flow(df):
#     """åµŒå¥—çš„ç‰¹å¾é€‰æ‹©æµç¨‹"""
#     st.subheader('ç‰¹å¾é€‰æ‹©')
#     with st.form('feature_selection_form'):
#         features = st.multiselect('é€‰æ‹©ç‰¹å¾å˜é‡', df.columns)
        
#         if st.form_submit_button('ç¡®è®¤é€‰æ‹©'):
#             if not features:
#                 st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾å˜é‡ï¼")
#                 return None
#             return df[features]  # è¿”å›é€‰æ‹©åçš„æ•°æ®
    
#     return df  # é»˜è®¤è¿”å›åŸæ•°æ®


# def ying_yong(pickle_model, df_new_copy, df_new):
#     try:
#         # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰feature_names_in_å±æ€§
#         if hasattr(pickle_model, 'feature_names_in_'):
#             required_features = pickle_model.feature_names_in_
#             # ç¡®ä¿æ•°æ®åŒ…å«æ‰€æœ‰éœ€è¦çš„ç‰¹å¾
#             missing_features = set(required_features) - set(df_new_copy.columns)
#             if missing_features:
#                 for feature in missing_features:
#                     df_new_copy[feature] = 0  # å¡«å……ç¼ºå¤±ç‰¹å¾ä¸º0
#             df_new_copy = df_new_copy[required_features]
        
#         y_pred = pickle_model.predict(df_new_copy.values)
#         df_new['predict'] = y_pred
#         st.dataframe(df_new)
#     except Exception as e:
#         st.error(f"é¢„æµ‹å‡ºé”™: {str(e)}")


# def main_workflow():
#     """ä¸»å·¥ä½œæµå‡½æ•°ï¼ˆåµŒå¥—è°ƒç”¨å…¶ä»–å‡½æ•°ï¼‰"""
#     uploaded_file0 = st.file_uploader('é€‰æ‹©æœ¬åœ°æ¨¡å‹', type=['pkl'])
#     # 1. åŠ è½½æ•°æ®
#     uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type=["csv"])
    
#     if (uploaded_file is not None) and (uploaded_file0 is not None):
#         # return None
#         pickle_model = pickle.load(uploaded_file0)
#         df = load_data(uploaded_file)
#         df_copy = df.copy()
#         if df_copy is not None:
#             # return None
        
#         # 2. æ•°æ®é¢„å¤„ç†ï¼ˆåµŒå¥—è°ƒç”¨ï¼‰
#             processed_df = data_preprocessing_flow(df_copy)
#             if processed_df is not None:
#             # 3. ç‰¹å¾é€‰æ‹©ï¼ˆåµŒå¥—è°ƒç”¨ï¼‰
#                 final_df = feature_selection_flow(processed_df)
#                 # if final_df is not None:
#                 # æ¨¡å‹çš„åº”ç”¨
#             ying_yong(pickle_model,final_df, df)

#                 # return ying_df
                

   

    
#     # return ying_df


# if __name__ == "__main__":
#     main_workflow()
#     # result_df = main_workflow()
#     # if result_df is not None:
#     #     st.write("æœ€ç»ˆæ•°æ®é›†é¢„è§ˆï¼š")
#     #     st.dataframe(result_df)

