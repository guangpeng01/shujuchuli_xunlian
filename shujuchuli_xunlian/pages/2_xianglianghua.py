import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
import os
from datetime import datetime
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import GradientBoostingRegressor


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å‘é‡åŒ–å¤„ç†",   
    layout="wide",    
    initial_sidebar_state="expanded"  
)
# ç¼“å­˜æ•°æ®åŠ è½½
@st.cache_data
def load_data(uploaded_file):
    try:
        return pd.read_csv(uploaded_file)
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return None


def data_preprocessing(df):
    """æ•°æ®é¢„å¤„ç†å‡½æ•°"""
    st.subheader('æ•°æ®é¢„å¤„ç†')
    
    if 'processed_data' not in st.session_state:
        st.session_state.processed_data = df.copy()

    
    with st.form('preprocessing_form'):   
        col1, col2 = st.columns(2)    
        
        with col1:
            columns_to_drop = st.multiselect(
                'é€‰æ‹©è¦åˆ é™¤çš„åˆ—',
                st.session_state.processed_data.columns,
                
                help="é€‰æ‹©ä¸éœ€è¦çš„ç‰¹å¾åˆ—"
            )
            
        with col2:
            categorical_cols = st.session_state.processed_data.select_dtypes(
                include=['object', 'category','int']).columns.tolist()  
            columns_to_encode = st.multiselect(
                'é€‰æ‹©è¦è¿›è¡Œç‹¬çƒ­ç¼–ç çš„åˆ—',
                categorical_cols,   
                
                help="é€‰æ‹©åˆ†ç±»å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç "
            )
        
        submitted = st.form_submit_button('åº”ç”¨é¢„å¤„ç†') 
    
    if submitted:
        try:
            
            if columns_to_drop:    
                st.session_state.processed_data = st.session_state.processed_data.drop(
                    columns=columns_to_drop)
            
          
            if columns_to_encode:    
                st.session_state.processed_data = pd.get_dummies(
                    st.session_state.processed_data, 
                    columns=columns_to_encode, 
                    dtype=int
                )
            
            st.success("é¢„å¤„ç†å®Œæˆï¼")
            show_correlation_matrix(st.session_state.processed_data)

            
        except Exception as e:
            st.error(f"é¢„å¤„ç†å‡ºé”™: {str(e)}")
    
    return st.session_state.processed_data    


def show_correlation_matrix(df):
    """æ˜¾ç¤ºç›¸å…³æ€§çŸ©é˜µ"""
    st.subheader('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ')
    try:
        corr_matrix = df.corr()  
        fig, ax = plt.subplots(figsize=(10,6))   
        sns.heatmap(
            corr_matrix,    
            annot=True,    
            fmt=".2f",     
            cmap='coolwarm',  
            center=0,    
            ax=ax      
        )
        # plt.title("ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾", pad=20)  
        st.pyplot(fig)    
    except Exception as e:
        st.warning(f"æ— æ³•è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ: {str(e)}")


def feature_selection(df):
    """ç‰¹å¾é€‰æ‹©ç•Œé¢"""
    st.subheader('ç‰¹å¾é€‰æ‹©')    
    
    
    if 'selected_features' not in st.session_state:
        st.session_state.selected_features = []
    if 'selected_target' not in st.session_state:
        st.session_state.selected_target = None
    
    
    with st.form('feature_selection_form'):
        col1, col2 = st.columns(2)
        
        with col1:
            features = st.multiselect(
                'é€‰æ‹©ç‰¹å¾å˜é‡',
                df.columns,
                default=st.session_state.selected_features,    
                key='feature_select'
            )
            
        with col2:
            target = st.selectbox(
                'é€‰æ‹©ç›®æ ‡å˜é‡',
                df.columns,
                index=df.columns.get_loc(st.session_state.selected_target) 
                if st.session_state.selected_target in df.columns else 0,
                key='target_select'
            )
        
        submitted = st.form_submit_button('ç¡®è®¤é€‰æ‹©')

        if submitted:
            if not features:
                st.error("âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾å˜é‡ï¼")
                return None, None
            
            if target in features:
                st.error("âŒ ç›®æ ‡å˜é‡ä¸èƒ½åŒæ—¶ä½œä¸ºç‰¹å¾å˜é‡ï¼")
                return None, None
            
            try:
                st.session_state.selected_features = features
                st.session_state.selected_target = target
                
                st.success("âœ… ç‰¹å¾é€‰æ‹©æœ‰æ•ˆï¼")
                return df[features].values, df[target].values
            except Exception as e:
                st.error(f"æ•°æ®é€‰æ‹©é”™è¯¯: {str(e)}")
                return None, None

    return None, None


# def auto_save_model(model):
#     """è‡ªåŠ¨ä¿å­˜æ¨¡å‹åˆ°å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•"""
#     try:
#         # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
#         script_dir = os.path.dirname(os.path.abspath(__file__))
        
#         # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
#         timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
#         filename = f"auto_model_{timestamp}.pkl"
#         save_path = os.path.join(script_dir, filename)
        
#         # ä¿å­˜æ¨¡å‹
#         with open(save_path, "wb") as file:
#             pickle.dump(model, file)
        
#         st.success(f"âœ… æ¨¡å‹å·²è‡ªåŠ¨ä¿å­˜åˆ°: {save_path}")
#         return True
#     except Exception as e:
#         st.error(f"âŒ è‡ªåŠ¨ä¿å­˜å¤±è´¥: {str(e)}")
#         return False

def auto_save_model(model):
    """è‡ªåŠ¨ä¿å­˜æ¨¡å‹å¹¶æä¾›æ˜ç¡®çš„ç”¨æˆ·æŒ‡å¼•"""
    try:
        # 1. åˆ›å»ºä¸“ç”¨ä¿å­˜ç›®å½•
        save_dir = os.path.join(os.path.expanduser("~"), "auto_saved_models")
        os.makedirs(save_dir, exist_ok=True)
        
        # 2. ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"model_{timestamp}.pkl"
        save_path = os.path.join(save_dir, filename)
        
        # 3. ä¿å­˜æ¨¡å‹æ–‡ä»¶
        with open(save_path, "wb") as file:
            pickle.dump(model, file)
        
        # 4. æ˜¾ç¤ºå®Œæ•´çš„ç”¨æˆ·æŒ‡å¼•
        st.success("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸï¼")
        
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯å¡ç‰‡
        with st.expander("ğŸ“ æ¨¡å‹æ–‡ä»¶ä¿¡æ¯", expanded=True):
            col1, col2 = st.columns([1, 3])
            with col1:
                st.metric("ä¿å­˜ä½ç½®", value="ç”¨æˆ·ç›®å½•/auto_saved_models")
            with col2:
                st.code(f"å®Œæ•´è·¯å¾„: {save_path}")
            
            st.write("å¦‚ä½•æ‰¾åˆ°è¿™ä¸ªæ–‡ä»¶ï¼š")
            st.markdown("""
            - **Windows**: æ‰“å¼€æ–‡ä»¶èµ„æºç®¡ç†å™¨ â†’ è¾“å…¥è·¯å¾„ `%USERPROFILE%\auto_saved_models`
            - **Mac/Linux**: æ‰“å¼€ç»ˆç«¯ â†’ è¿è¡Œ `open ~/auto_saved_models` æˆ– `cd ~/auto_saved_models`
            """)
        
        # 5. ç›´æ¥æä¾›ä¸‹è½½æŒ‰é’®
        with open(save_path, "rb") as file:
            st.download_button(
                label="â¬‡ï¸ ç«‹å³ä¸‹è½½æ¨¡å‹æ–‡ä»¶",
                data=file,
                file_name=filename,
                mime="application/octet-stream"
            )
        
        return True
    except Exception as e:
        st.error(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")
        st.error("è¯·å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ¡ˆï¼š")
        st.markdown("""
        1. æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³
        2. ç¡®ä¿æ‚¨æœ‰å†™å…¥æƒé™ï¼ˆç‰¹åˆ«æ˜¯Linux/Macç³»ç»Ÿï¼‰
        3. å°è¯•æ‰‹åŠ¨æŒ‡å®šä¿å­˜ä½ç½®ï¼š
        """)
        
        # æ·»åŠ æ‰‹åŠ¨é€‰æ‹©è·¯å¾„çš„å¤‡ç”¨æ–¹æ¡ˆ
        custom_path = st.text_input("æˆ–è¾“å…¥è‡ªå®šä¹‰ä¿å­˜è·¯å¾„ï¼ˆå¦‚ï¼šC:/models/ï¼‰")
        if st.button("æ‰‹åŠ¨ä¿å­˜"):
            if custom_path:
                try:
                    os.makedirs(custom_path, exist_ok=True)
                    custom_save = os.path.join(custom_path, filename)
                    with open(custom_save, "wb") as f:
                        pickle.dump(model, f)
                    st.success(f"æ‰‹åŠ¨ä¿å­˜æˆåŠŸï¼è·¯å¾„: {custom_save}")
                except Exception as manual_error:
                    st.error(f"æ‰‹åŠ¨ä¿å­˜å¤±è´¥: {str(manual_error)}")
        
        return False

def train_random_forest(X, y):
    """è®­ç»ƒæ¨¡å‹"""
    st.subheader('æ¨¡å‹è®­ç»ƒ')
     # â€‹æƒ°æ€§åˆå§‹åŒ–  ä»…åœ¨ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶åˆå§‹åŒ–ï¼Œåç»­ä¿ç•™è®­ç»ƒç»“æœ
    if 'training_results' not in st.session_state:
        st.session_state.training_results = None
    try:
        st.session_state.training_results = None    # â€‹å¼ºåˆ¶é‡ç½® æ¯æ¬¡è°ƒç”¨å‡½æ•°æ—¶æ¸…ç©ºå†å²ç»“æœ
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )
      
        if len(np.unique(y_train)) < 6:
            # è®­ç»ƒæ¨¡å‹
            model = RandomForestClassifier()
            model = model.fit(X_train, y_train)
            
            # è¯„ä¼°æ¨¡å‹
            y_pred = model.predict(X_test)  # è·å–é¢„æµ‹ç»“æœ
            results = {
                'model': model,
                'accuracy': accuracy_score(y_test, y_pred),   # è¯„ä»·å¾—åˆ†
                'f1': f1_score(y_test, y_pred),
                'confusion_matrix': confusion_matrix(y_test, y_pred),
                'features': X.shape[1]
            }
    
        else:
           
            model = GradientBoostingRegressor()  
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)  # è·å–é¢„æµ‹ç»“æœ
            # mse = mean_squared_error(y_test, y_pred)
            # rmse = mean_squared_error(y_test, y_pred, squared=False)
            r2 = r2_score(y_test, y_pred)
            results = {
                'model': model,
                # 'mean': mse,
                'r2': r2,
                'features': X.shape[1]
            }

        # ä¿å­˜ç»“æœ
        st.session_state.training_results = results
        st.session_state.model = model
        st.success('è®­ç»ƒå®Œæˆï¼')
        if 'accuracy' in results:  # åˆ†ç±»ä»»åŠ¡
            st.metric("å‡†ç¡®ç‡", f"{results['accuracy']:.4f}")
            st.metric("F1åˆ†æ•°", f"{results['f1']:.4f}")
            st.write("æ··æ·†çŸ©é˜µ:", results['confusion_matrix'])
        else:  # å›å½’ä»»åŠ¡
            # st.metric("å‡æ–¹è¯¯å·®", f"{results['mean']:.4f}")
            st.metric("RÂ²åˆ†æ•°", f"{results['r2']:.4f}")

        auto_save_model(model)  # è°ƒç”¨è‡ªåŠ¨ä¿å­˜å‡½æ•°
       
    except Exception as e:
        st.error(f"è®­ç»ƒå¼‚å¸¸: {str(e)}")
    
    # è‡ªåŠ¨æ˜¾ç¤ºè®­ç»ƒç»“æœ

    return None


def clear_all():
    """æ¸…ç©ºä¼šè¯çŠ¶æ€å’Œç¼“å­˜"""
    # æ¸…ç©ºä¼šè¯çŠ¶æ€
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    
    # æ¸…ç©ºç¼“å­˜ï¼ˆå¦‚æœæœ‰ä½¿ç”¨ï¼‰
    st.cache_data.clear()
    st.cache_resource.clear()
    

def main():
    st.title("æ•°æ®å‘é‡åŒ–")   

    uploaded_file = st.file_uploader(
        "ä¸Šä¼ CSVæ–‡ä»¶",
        type=["csv"],
        help="è¯·ä¸Šä¼ åŒ…å«è®­ç»ƒæ•°æ®çš„CSVæ–‡ä»¶"
    )
    # clear_all()
    if uploaded_file is not None:
        df = load_data(uploaded_file)
        if df is not None:
            with st.expander("ğŸ” æŸ¥çœ‹åŸå§‹æ•°æ®", expanded=True):
                st.dataframe(df)
            
            df_processed = data_preprocessing(df)

            if df_processed is not None:
                # ç‰¹å¾é€‰æ‹©
                X, y = feature_selection(df_processed)
                
                if X is not None and y is not None:
                    train_random_forest(X, y)

                    clear_all()
    # return None                


if __name__ == "__main__":

    main()
